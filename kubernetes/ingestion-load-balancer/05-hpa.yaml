apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ingestion-service-hpa
  namespace: ingestion-lb
  labels:
    app: ingestion-service
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ingestion-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  # Scale based on CPU utilization
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  # Scale based on memory utilization  
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  # Optional: Scale based on custom metrics (requires metrics server)
  # - type: Pods
  #   pods:
  #     metric:
  #       name: grpc_requests_per_second
  #     target:
  #       type: AverageValue
  #       averageValue: "1000"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # Wait 5 minutes before scaling down
      policies:
      - type: Percent
        value: 50  # Scale down by max 50% of current replicas
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0  # Scale up immediately when needed
      policies:
      - type: Percent
        value: 100  # Can double the replicas
        periodSeconds: 15
      - type: Pods
        value: 4  # Or add max 4 pods at once
        periodSeconds: 15
      selectPolicy: Max  # Use the more aggressive policy